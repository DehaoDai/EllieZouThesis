scale_color_manual(values = color_palette, guide = guide_legend(override.aes = list(fill = NA))) +
ylab(TeX("$|\\widehat{\\beta}_\\lambda - \\beta^*|_1$"))+
xlab(TeX("$S\\sqrt{(\\log d)^{1+2\\nu}/n}, \\nu = 1/2$"))+
scale_x_continuous(breaks = seq(0.3, 0.6, by = 0.05))+
scale_y_continuous(breaks = seq(0, 1.6, by = 0.2))+
theme_bw()+
theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank())+
theme(legend.position = c(0.8,0.6))+
theme(legend.title = element_blank())
setwd("~/Documents/GitHub/EllieZouThesis/simulation")
setwd("~/Documents/GitHub/EllieZouThesis/real data")
##-------------------------Read Data and Data processing----------------------##
X = read.csv('realdata_processed.csv')
date = X[,1]
X = X[,-1]
X = data.frame(X)
nnn = colnames(X)
nrow(Z)
nrow(X)
##----------------------Loading required packages-----------------------------##
library(glmnet)
set.seed(914812)
T = 120  ## moving window approach, 30 years as window size
M = nrow(X)-T  ## predict sample size
N = 225 ## number of columns
length(nnn)
nnn
N = 226 ## number of columns
## The following values are initialized for storing prediction difference, R^2,
## predicted values, obtained from different methods like FARMTS, LASSO, RIDGE,
## Sample Mean, PCR, respectively.
##----------------------Initialize M-by-N Matrix------------------------------##
Pred.FARMTS = matrix(0,M,N)                     ## FARMTS for estimation and prediction
Pred.LASSO = matrix(0,M,N)                      ## Lasso for prediction
Pred.MEAN = matrix(0,M,N)                       ## MEAN for prediction
Pred.PCR = matrix(0,M,N)                        ## PCR for prediction
Pred.RIDGE=matrix(0,M,N)                        ## Ridge Regression for prediction
## Out-of-sample R^2
##----------------------------------------------------------------------------##
R2.FARMTS = numeric(N)                          ## FARMTS
R2.LASSO = numeric(N)                           ## LASSO
R2.PCR = numeric(N)                             ## PCR
R2.RIDGE = numeric(N)                           ## Ridge
## Prediction values
##----------------------------------------------------------------------------##
Prvalue_FARMTS=matrix(0,M,N)                    ## FARMTS
Prvalue_LASSO=matrix(0,M,N)                     ## LASSO
Prvalue_PCR=matrix(0,M,N)                       ## PCR
Prvalue_MEAN=matrix(0,M,N)                      ## Sample MEAN
Prvalue_RIDGE=matrix(0,M,N)                     ## Ridge Regression
## Predictions are conducted Next
#j = which(nnn %in% 'HOUSTW') #HOUSTW
#j = which(nnn %in% 'IPNCONGD')
for(j in 1:length(nnn)){
D = X[,-j]
Y = X[,j]
for(i in 1:M){
idx = i:(i+T-1) ## Moving window prediction, every window has length T
x = D[idx,] ## Training Data Covariate
y = Y[idx]  ## Training Data Response
x.pred = D[i+T,] ## Prediction Covariate
y.pred = Y[i+T] ## Prediction Response
##----------------------------Do Data Normalization----------------------------##
x.mu = colMeans(x)
x.sd = as.numeric(apply(x,2,sd))
y.mu = mean(y)
Prvalue_MEAN[i,j]=y.mu
y.sd = sd(y)
x = t((t(x)-x.mu)/x.sd)
y = (y-y.mu)/y.sd
x.pred = (x.pred-x.mu)/x.sd
x.pred = unlist(x.pred)
y.pred = (y.pred-y.mu)/y.sd
##-----------------------------------------------------------------------------##
## Sample Mean
Pred.MEAN[i,j] = (y.pred*y.sd)^2
## Lasso
cv.fit = cv.glmnet(x,y,intercept=FALSE)
lambda.fit = cv.fit$lambda.min
fit_model = glmnet(x,y,intercept=FALSE,lambda=lambda.fit)  ## Lasso Estimation
beta.hat = as.vector(fit_model$beta)
Pred.LASSO[i,j] = (y.pred-sum(x.pred*beta.hat))^2*y.sd^2
Prvalue_LASSO[i,j]=sum(x.pred*beta.hat)*y.sd+y.mu    ## Lasso Prediction
## Ridge
cv.fit = cv.glmnet(x,y,intercept=FALSE,alpha=0)
lambda.fit = cv.fit$lambda.1se
fit_model = glmnet(x,y,intercept=FALSE,lambda=lambda.fit,alpha=0)  ## Ridge estimation
beta.hat = as.vector(fit_model$beta)
Pred.RIDGE[i,j] = (y.pred-sum(x.pred*beta.hat))^2*y.sd^2
Prvalue_RIDGE[i,j]=sum(x.pred*beta.hat)*y.sd+y.mu ## Ridge Prediction
##Factor Estimation
Sigma.x = tcrossprod(x)/T      #covariance matrix
eigenx = eigen(Sigma.x)
eigvec = eigenx$vectors        #Eigen vector
eigvalue = eigenx$values       #Eigen values
K.hat = max(2,which.min(diff(log(eigvalue[1:10]))))      ## Factor estimation
F.hat = eigvec[,1:K.hat]*sqrt(T)        #Estimated Factor
B.hat = t(t(F.hat)%*%x)/T          #Estimated Factor Loading
U.hat = x-F.hat%*%t(B.hat)        #Estimated idiosyncratic component
# FARMTS
lmY.F = lm(y~F.hat-1)
gamma.hat = coef(lmY.F)
Y.tilde = resid(lmY.F)
cv.fit.U = cv.glmnet(U.hat,Y.tilde,intercept=FALSE)
lambda.fit.U = cv.fit.U$lambda.min #tuning parameter selection
fit.U = glmnet(U.hat,Y.tilde,intercept=FALSE,lambda=lambda.fit.U) ## Estimation
beta.hat.U = as.vector(fit.U$beta) #Obtain the fitted beta
lmx.B = lm(x.pred~B.hat-1)
f.pred = coef(lmx.B)
u.pred = resid(lmx.B)
Pred.FARMTS[i,j] = (y.pred-sum(f.pred*gamma.hat)-sum(u.pred*beta.hat.U))^2*y.sd^2 #FARM prediction Difference with the true value
Prvalue_FARMTS[i,j]=(sum(f.pred*gamma.hat)+sum(u.pred*beta.hat.U))*y.sd+y.mu  #FARM predicted value
Pred.PCR[i,j] = (y.pred-sum(f.pred*gamma.hat))^2*y.sd^2     #PCR prediction Difference with the true value
Prvalue_PCR[i,j]=sum(f.pred*gamma.hat)*y.sd+y.mu           #PCR predicted value
}
R2.FARMTS[j] = 1-sum(Pred.FARMTS[,j])/sum(Pred.MEAN[,j])
print(R2.FARMTS[j])                    #Output R^2 value for FARM
R2.PCR[j] = 1-sum(Pred.PCR[,j])/sum(Pred.MEAN[,j])
print(R2.PCR[j])                   #Output R^2 value for PCR
R2.LASSO[j] = 1-sum(Pred.LASSO[,j])/sum(Pred.MEAN[,j])
print(R2.LASSO[j])                 #Output R^2 value for LASSO
R2.RIDGE[j] = 1-sum(Pred.RIDGE[,j])/sum(Pred.MEAN[,j])
print(R2.RIDGE[j])                 #Output R^2 value for RIDGE
}
M
j = length(nnn)
D = X[,-j]
Y = X[,j]
for(i in 1:M){
idx = i:(i+T-1) ## Moving window prediction, every window has length T
x = D[idx,] ## Training Data Covariate
y = Y[idx]  ## Training Data Response
x.pred = D[i+T,] ## Prediction Covariate
y.pred = Y[i+T] ## Prediction Response
##----------------------------Do Data Normalization----------------------------##
x.mu = colMeans(x)
x.sd = as.numeric(apply(x,2,sd))
y.mu = mean(y)
Prvalue_MEAN[i,j]=y.mu
y.sd = sd(y)
x = t((t(x)-x.mu)/x.sd)
y = (y-y.mu)/y.sd
x.pred = (x.pred-x.mu)/x.sd
x.pred = unlist(x.pred)
y.pred = (y.pred-y.mu)/y.sd
##-----------------------------------------------------------------------------##
## Sample Mean
Pred.MEAN[i,j] = (y.pred*y.sd)^2
## Lasso
cv.fit = cv.glmnet(x,y,intercept=FALSE)
lambda.fit = cv.fit$lambda.min
fit_model = glmnet(x,y,intercept=FALSE,lambda=lambda.fit)  ## Lasso Estimation
beta.hat = as.vector(fit_model$beta)
Pred.LASSO[i,j] = (y.pred-sum(x.pred*beta.hat))^2*y.sd^2
Prvalue_LASSO[i,j]=sum(x.pred*beta.hat)*y.sd+y.mu    ## Lasso Prediction
## Ridge
cv.fit = cv.glmnet(x,y,intercept=FALSE,alpha=0)
lambda.fit = cv.fit$lambda.1se
fit_model = glmnet(x,y,intercept=FALSE,lambda=lambda.fit,alpha=0)  ## Ridge estimation
beta.hat = as.vector(fit_model$beta)
Pred.RIDGE[i,j] = (y.pred-sum(x.pred*beta.hat))^2*y.sd^2
Prvalue_RIDGE[i,j]=sum(x.pred*beta.hat)*y.sd+y.mu ## Ridge Prediction
##Factor Estimation
Sigma.x = tcrossprod(x)/T      #covariance matrix
eigenx = eigen(Sigma.x)
eigvec = eigenx$vectors        #Eigen vector
eigvalue = eigenx$values       #Eigen values
K.hat = max(2,which.min(diff(log(eigvalue[1:10]))))      ## Factor estimation
F.hat = eigvec[,1:K.hat]*sqrt(T)        #Estimated Factor
B.hat = t(t(F.hat)%*%x)/T          #Estimated Factor Loading
U.hat = x-F.hat%*%t(B.hat)        #Estimated idiosyncratic component
# FARMTS
lmY.F = lm(y~F.hat-1)
gamma.hat = coef(lmY.F)
Y.tilde = resid(lmY.F)
cv.fit.U = cv.glmnet(U.hat,Y.tilde,intercept=FALSE)
lambda.fit.U = cv.fit.U$lambda.min #tuning parameter selection
fit.U = glmnet(U.hat,Y.tilde,intercept=FALSE,lambda=lambda.fit.U) ## Estimation
beta.hat.U = as.vector(fit.U$beta) #Obtain the fitted beta
lmx.B = lm(x.pred~B.hat-1)
f.pred = coef(lmx.B)
u.pred = resid(lmx.B)
Pred.FARMTS[i,j] = (y.pred-sum(f.pred*gamma.hat)-sum(u.pred*beta.hat.U))^2*y.sd^2 #FARM prediction Difference with the true value
Prvalue_FARMTS[i,j]=(sum(f.pred*gamma.hat)+sum(u.pred*beta.hat.U))*y.sd+y.mu  #FARM predicted value
Pred.PCR[i,j] = (y.pred-sum(f.pred*gamma.hat))^2*y.sd^2     #PCR prediction Difference with the true value
Prvalue_PCR[i,j]=sum(f.pred*gamma.hat)*y.sd+y.mu           #PCR predicted value
}
i = 1
idx = i:(i+T-1) ## Moving window prediction, every window has length T
x = D[idx,] ## Training Data Covariate
y = Y[idx]  ## Training Data Response
x.pred = D[i+T,] ## Prediction Covariate
y.pred = Y[i+T] ## Prediction Response
##----------------------------Do Data Normalization----------------------------##
x.mu = colMeans(x)
x.sd = as.numeric(apply(x,2,sd))
y.mu = mean(y)
Prvalue_MEAN[i,j]=y.mu
y.sd = sd(y)
x = t((t(x)-x.mu)/x.sd)
y = (y-y.mu)/y.sd
x.pred = (x.pred-x.mu)/x.sd
x.pred = unlist(x.pred)
y.pred = (y.pred-y.mu)/y.sd
## Sample Mean
Pred.MEAN[i,j] = (y.pred*y.sd)^2
## Lasso
cv.fit = cv.glmnet(x,y,intercept=FALSE)
lambda.fit = cv.fit$lambda.min
fit_model = glmnet(x,y,intercept=FALSE,lambda=lambda.fit)  ## Lasso Estimation
beta.hat = as.vector(fit_model$beta)
Pred.LASSO[i,j] = (y.pred-sum(x.pred*beta.hat))^2*y.sd^2
Prvalue_LASSO[i,j]=sum(x.pred*beta.hat)*y.sd+y.mu    ## Lasso Prediction
## Ridge
cv.fit = cv.glmnet(x,y,intercept=FALSE,alpha=0)
lambda.fit = cv.fit$lambda.1se
fit_model = glmnet(x,y,intercept=FALSE,lambda=lambda.fit,alpha=0)  ## Ridge estimation
beta.hat = as.vector(fit_model$beta)
Pred.RIDGE[i,j] = (y.pred-sum(x.pred*beta.hat))^2*y.sd^2
Prvalue_RIDGE[i,j]=sum(x.pred*beta.hat)*y.sd+y.mu ## Ridge Prediction
##Factor Estimation
Sigma.x = tcrossprod(x)/T      #covariance matrix
eigenx = eigen(Sigma.x)
eigvec = eigenx$vectors        #Eigen vector
eigvalue = eigenx$values       #Eigen values
K.hat = max(2,which.min(diff(log(eigvalue[1:10]))))      ## Factor estimation
F.hat = eigvec[,1:K.hat]*sqrt(T)        #Estimated Factor
B.hat = t(t(F.hat)%*%x)/T          #Estimated Factor Loading
U.hat = x-F.hat%*%t(B.hat)        #Estimated idiosyncratic component
# FARMTS
lmY.F = lm(y~F.hat-1)
gamma.hat = coef(lmY.F)
Y.tilde = resid(lmY.F)
cv.fit.U = cv.glmnet(U.hat,Y.tilde,intercept=FALSE)
lambda.fit.U = cv.fit.U$lambda.min #tuning parameter selection
fit.U = glmnet(U.hat,Y.tilde,intercept=FALSE,lambda=lambda.fit.U) ## Estimation
beta.hat.U = as.vector(fit.U$beta) #Obtain the fitted beta
lmx.B = lm(x.pred~B.hat-1)
f.pred = coef(lmx.B)
u.pred = resid(lmx.B)
Pred.FARMTS[i,j] = (y.pred-sum(f.pred*gamma.hat)-sum(u.pred*beta.hat.U))^2*y.sd^2 #FARM prediction Difference with the true value
Prvalue_FARMTS[i,j]=(sum(f.pred*gamma.hat)+sum(u.pred*beta.hat.U))*y.sd+y.mu  #FARM predicted value
Pred.PCR[i,j] = (y.pred-sum(f.pred*gamma.hat))^2*y.sd^2     #PCR prediction Difference with the true value
Prvalue_PCR[i,j]=sum(f.pred*gamma.hat)*y.sd+y.mu           #PCR predicted value
i = M
idx = i:(i+T-1) ## Moving window prediction, every window has length T
x = D[idx,] ## Training Data Covariate
y = Y[idx]  ## Training Data Response
x.pred = D[i+T,] ## Prediction Covariate
y.pred = Y[i+T] ## Prediction Response
##----------------------------Do Data Normalization----------------------------##
x.mu = colMeans(x)
x.sd = as.numeric(apply(x,2,sd))
y.mu = mean(y)
Prvalue_MEAN[i,j]=y.mu
y.sd = sd(y)
x = t((t(x)-x.mu)/x.sd)
y = (y-y.mu)/y.sd
x.pred = (x.pred-x.mu)/x.sd
x.pred = unlist(x.pred)
y.pred = (y.pred-y.mu)/y.sd
## Sample Mean
Pred.MEAN[i,j] = (y.pred*y.sd)^2
## Lasso
cv.fit = cv.glmnet(x,y,intercept=FALSE)
lambda.fit = cv.fit$lambda.min
fit_model = glmnet(x,y,intercept=FALSE,lambda=lambda.fit)  ## Lasso Estimation
x
X
##-------------------------Read Data and Data processing----------------------##
X = read.csv('realdata_processed.csv')
date = X[,1]
X = X[,-1]
X = data.frame(X)
nnn = colnames(X)
##----------------------Loading required packages-----------------------------##
library(glmnet)
set.seed(914812)
T = 120  ## moving window approach, 30 years as window size
M = nrow(X)-T  ## predict sample size
N = 226 ## number of columns
## The following values are initialized for storing prediction difference, R^2,
## predicted values, obtained from different methods like FARMTS, LASSO, RIDGE,
## Sample Mean, PCR, respectively.
##----------------------Initialize M-by-N Matrix------------------------------##
Pred.FARMTS = matrix(0,M,N)                     ## FARMTS for estimation and prediction
Pred.LASSO = matrix(0,M,N)                      ## Lasso for prediction
Pred.MEAN = matrix(0,M,N)                       ## MEAN for prediction
Pred.PCR = matrix(0,M,N)                        ## PCR for prediction
Pred.RIDGE=matrix(0,M,N)                        ## Ridge Regression for prediction
## Out-of-sample R^2
##----------------------------------------------------------------------------##
R2.FARMTS = numeric(N)                          ## FARMTS
R2.LASSO = numeric(N)                           ## LASSO
R2.PCR = numeric(N)                             ## PCR
R2.RIDGE = numeric(N)                           ## Ridge
## Prediction values
##----------------------------------------------------------------------------##
Prvalue_FARMTS=matrix(0,M,N)                    ## FARMTS
Prvalue_LASSO=matrix(0,M,N)                     ## LASSO
Prvalue_PCR=matrix(0,M,N)                       ## PCR
Prvalue_MEAN=matrix(0,M,N)                      ## Sample MEAN
Prvalue_RIDGE=matrix(0,M,N)                     ## Ridge Regression
## Predictions are conducted Next
#j = which(nnn %in% 'HOUSTW') #HOUSTW
#j = which(nnn %in% 'IPNCONGD')
for(j in 1:length(nnn)){
D = X[,-j]
Y = X[,j]
for(i in 1:M){
idx = i:(i+T-1) ## Moving window prediction, every window has length T
x = D[idx,] ## Training Data Covariate
y = Y[idx]  ## Training Data Response
x.pred = D[i+T,] ## Prediction Covariate
y.pred = Y[i+T] ## Prediction Response
##----------------------------Do Data Normalization----------------------------##
x.mu = colMeans(x)
x.sd = as.numeric(apply(x,2,sd))
y.mu = mean(y)
Prvalue_MEAN[i,j]=y.mu
y.sd = sd(y)
x = t((t(x)-x.mu)/x.sd)
y = (y-y.mu)/y.sd
x.pred = (x.pred-x.mu)/x.sd
x.pred = unlist(x.pred)
y.pred = (y.pred-y.mu)/y.sd
##-----------------------------------------------------------------------------##
## Sample Mean
Pred.MEAN[i,j] = (y.pred*y.sd)^2
## Lasso
cv.fit = cv.glmnet(x,y,intercept=FALSE)
lambda.fit = cv.fit$lambda.min
fit_model = glmnet(x,y,intercept=FALSE,lambda=lambda.fit)  ## Lasso Estimation
beta.hat = as.vector(fit_model$beta)
Pred.LASSO[i,j] = (y.pred-sum(x.pred*beta.hat))^2*y.sd^2
Prvalue_LASSO[i,j]=sum(x.pred*beta.hat)*y.sd+y.mu    ## Lasso Prediction
## Ridge
cv.fit = cv.glmnet(x,y,intercept=FALSE,alpha=0)
lambda.fit = cv.fit$lambda.1se
fit_model = glmnet(x,y,intercept=FALSE,lambda=lambda.fit,alpha=0)  ## Ridge estimation
beta.hat = as.vector(fit_model$beta)
Pred.RIDGE[i,j] = (y.pred-sum(x.pred*beta.hat))^2*y.sd^2
Prvalue_RIDGE[i,j]=sum(x.pred*beta.hat)*y.sd+y.mu ## Ridge Prediction
##Factor Estimation
Sigma.x = tcrossprod(x)/T      #covariance matrix
eigenx = eigen(Sigma.x)
eigvec = eigenx$vectors        #Eigen vector
eigvalue = eigenx$values       #Eigen values
K.hat = max(2,which.min(diff(log(eigvalue[1:10]))))      ## Factor estimation
F.hat = eigvec[,1:K.hat]*sqrt(T)        #Estimated Factor
B.hat = t(t(F.hat)%*%x)/T          #Estimated Factor Loading
U.hat = x-F.hat%*%t(B.hat)        #Estimated idiosyncratic component
# FARMTS
lmY.F = lm(y~F.hat-1)
gamma.hat = coef(lmY.F)
Y.tilde = resid(lmY.F)
cv.fit.U = cv.glmnet(U.hat,Y.tilde,intercept=FALSE)
lambda.fit.U = cv.fit.U$lambda.min #tuning parameter selection
fit.U = glmnet(U.hat,Y.tilde,intercept=FALSE,lambda=lambda.fit.U) ## Estimation
beta.hat.U = as.vector(fit.U$beta) #Obtain the fitted beta
lmx.B = lm(x.pred~B.hat-1)
f.pred = coef(lmx.B)
u.pred = resid(lmx.B)
Pred.FARMTS[i,j] = (y.pred-sum(f.pred*gamma.hat)-sum(u.pred*beta.hat.U))^2*y.sd^2 #FARM prediction Difference with the true value
Prvalue_FARMTS[i,j]=(sum(f.pred*gamma.hat)+sum(u.pred*beta.hat.U))*y.sd+y.mu  #FARM predicted value
Pred.PCR[i,j] = (y.pred-sum(f.pred*gamma.hat))^2*y.sd^2     #PCR prediction Difference with the true value
Prvalue_PCR[i,j]=sum(f.pred*gamma.hat)*y.sd+y.mu           #PCR predicted value
}
R2.FARMTS[j] = 1-sum(Pred.FARMTS[,j])/sum(Pred.MEAN[,j])
print(R2.FARMTS[j])                    #Output R^2 value for FARM
R2.PCR[j] = 1-sum(Pred.PCR[,j])/sum(Pred.MEAN[,j])
print(R2.PCR[j])                   #Output R^2 value for PCR
R2.LASSO[j] = 1-sum(Pred.LASSO[,j])/sum(Pred.MEAN[,j])
print(R2.LASSO[j])                 #Output R^2 value for LASSO
R2.RIDGE[j] = 1-sum(Pred.RIDGE[,j])/sum(Pred.MEAN[,j])
print(R2.RIDGE[j])                 #Output R^2 value for RIDGE
}
write.csv("R2.FARMTS.csv", R2.FARMTS)
write.csv(R2.FARMTS, "R2.FARMTS.csv")
write.csv(R2.PCR, "R2.PCR.csv")
write.csv(R2.LASSO, "R2.LASSO.csv")
write.csv(R2.RIDGE,"R2.RIDGE.csv")
jjj = which(R2.FARMTS>R2.LASSO & R2.PCR >0 &R2.RIDGE>0 & R2.LASSO>max(R2.PCR,R2.RIDGE))
jjj
jjj2 = c(12,13,33,51,84,132,133,147,158)
R2.FARMTS(jjj2)
R2.FARMTS[jjj2]
R2.LASSO[jjj2]
nnn[51]
R2.PCR[jjj2]
R2.RIDGE[jjj2]
R2.FARMTS[jjj2]-R2.LASSO[jjj2]
qqnorm(X[,51])
qqline(X[,51])
nnn[13]
nnn[51]
qqnorm(X[,13])
qqline(X[,13])
R2.FARMTS[13]
R2.LASSO[13]
nnn[13]
R2.PCR[13]
R2.RIDGE[13]
R2.FARMTS[51]
R2.LASSO[51]
R2.PCR[51]
R2.RIDGE[51]
nrow(X)
j = 13
date <- as.Date(date, "%m/%d/%Y")
plot(date[(T+1):nrow(X)],Y[(T+1):nrow(X)], type = "l",xlab = "",ylab = "", col = 1)
a = 3
lines(date[(T+1):nrow(X)],Prvalue_FARMTS[,j], lty = 2, col = "red")
lines(date[(T+1):nrow(X)],Prvalue_LASSO[,j], lty = a, col = "green")
lines(date[(T+1):nrow(X)],Prvalue_RIDGE[,j], lty = a, col = "purple")
lines(date[(T+1):nrow(X)],Prvalue_MEAN[,j],lty = a,col = "blue")
lines(date[(T+1):nrow(X)],Prvalue_PCR[,j], lty = a, col = "orange")
Prvalue_FARMTS[,1]
Y = X[,j]
plot(date[(T+1):nrow(X)],Y[(T+1):nrow(X)], type = "l",xlab = "",ylab = "", col = 1)
a = 3
lines(date[(T+1):nrow(X)],Prvalue_FARMTS[,j], lty = 2, col = "red")
lines(date[(T+1):nrow(X)],Prvalue_LASSO[,j], lty = a, col = "green")
lines(date[(T+1):nrow(X)],Prvalue_RIDGE[,j], lty = a, col = "purple")
lines(date[(T+1):nrow(X)],Prvalue_MEAN[,j],lty = a,col = "blue")
lines(date[(T+1):nrow(X)],Prvalue_PCR[,j], lty = a, col = "orange")
Y = X[,51]
plot(date[(T+1):nrow(X)],Y[(T+1):nrow(X)], type = "l",xlab = "",ylab = "", col = 1)
a = 3
lines(date[(T+1):nrow(X)],Prvalue_FARMTS[,j], lty = 2, col = "red")
lines(date[(T+1):nrow(X)],Prvalue_LASSO[,j], lty = a, col = "green")
lines(date[(T+1):nrow(X)],Prvalue_RIDGE[,j], lty = a, col = "purple")
lines(date[(T+1):nrow(X)],Prvalue_MEAN[,j],lty = a,col = "blue")
lines(date[(T+1):nrow(X)],Prvalue_PCR[,j], lty = a, col = "orange")
j = 51
plot(date[(T+1):nrow(X)],Y[(T+1):nrow(X)], type = "l",xlab = "",ylab = "", col = 1)
a = 3
lines(date[(T+1):nrow(X)],Prvalue_FARMTS[,j], lty = 2, col = "red")
lines(date[(T+1):nrow(X)],Prvalue_LASSO[,j], lty = a, col = "green")
lines(date[(T+1):nrow(X)],Prvalue_RIDGE[,j], lty = a, col = "purple")
lines(date[(T+1):nrow(X)],Prvalue_MEAN[,j],lty = a,col = "blue")
lines(date[(T+1):nrow(X)],Prvalue_PCR[,j], lty = a, col = "orange")
nnn[51]
13
nnn[13]
j = 13
Y = X[,13]
plot(date[(T+1):nrow(X)],Y[(T+1):nrow(X)], type = "l",xlab = "",ylab = "", col = 1)
a = 3
lines(date[(T+1):nrow(X)],Prvalue_FARMTS[,j], lty = 2, col = "red")
lines(date[(T+1):nrow(X)],Prvalue_LASSO[,j], lty = a, col = "green")
lines(date[(T+1):nrow(X)],Prvalue_RIDGE[,j], lty = a, col = "purple")
lines(date[(T+1):nrow(X)],Prvalue_MEAN[,j],lty = a,col = "blue")
lines(date[(T+1):nrow(X)],Prvalue_PCR[,j], lty = a, col = "orange")
library(readr)
mat <- read_csv("~/Downloads/mat (3).csv",
col_types = cols(...1 = col_skip()))
library(readr)
mat2 <- read_csv("~/Downloads/mat2 (3).csv",
col_types = cols(...1 = col_skip()))
View(mat2)
mat = as.matrix(mat)
mat2 = as.matrix(mat2)
## draw
meanline = rowMeans(mat)
sd_1 = apply(mat[,1:re],1, sd)
lowerbound = meanline - sd_1
upperbound = meanline + sd_1
meanline2 = rowMeans(mat2)
sd_2 = apply(mat2[,1:re],1, sd)
lowerbound2 = meanline2 - sd_2
upperbound2 = meanline2 + sd_2
## draw
data <- data.frame(x = rep(ratio, 2),
y = c(meanline, meanline2),
group = rep(c("FARM_TS","LASSO"), each = length(ratio)),
lower_interval = c(lowerbound, lowerbound2),
upper_interval = c(upperbound, upperbound2))
color_palette <- c("red", "blue")
## draw
data <- data.frame(x = rep(ratio, 2),
y = c(meanline, meanline2),
group = rep(c("FATS","LASSO"), each = length(ratio)),
lower_interval = c(lowerbound, lowerbound2),
upper_interval = c(upperbound, upperbound2))
color_palette <- c("red", "blue")
ggplot(data, aes(x = x, y = y)) +
geom_ribbon(aes(ymin = lower_interval, ymax = upper_interval, fill = group), alpha = 0.3) +
geom_line(data = subset(data, group == "FATS"), aes(color = group)) +
geom_line(data = subset(data, group == "LASSO"), aes(color = group)) +
scale_color_manual(values = color_palette, guide = guide_legend(override.aes = list(fill = NA))) +
ylab(TeX("$|\\widehat{\\beta}_\\lambda - \\beta^*|_1$"))+
xlab(TeX("$S\\sqrt{(\\log p)^{1+2\\nu}/n}, \\nu = 1/2$"))+
scale_x_continuous(breaks = seq(0.3, 0.6, by = 0.05))+
scale_y_continuous(breaks = seq(0, 1.6, by = 0.2))+
theme_bw()+
theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank())+
theme(legend.position = c(0.8,0.7))+
theme(legend.title = element_blank())
ggplot(data, aes(x = x, y = y)) +
geom_ribbon(aes(ymin = lower_interval, ymax = upper_interval, fill = group), alpha = 0.3) +
geom_line(data = subset(data, group == "FATS"), aes(color = group)) +
geom_line(data = subset(data, group == "LASSO"), aes(color = group)) +
scale_color_manual(values = color_palette, guide = guide_legend(override.aes = list(fill = NA))) +
ylab(TeX("$|\\widehat{\\beta}_\\lambda - \\beta^*|_1$"))+
xlab(TeX("$S\\sqrt{(\\log p)^{1+2\\nu}/n}, \\nu = 1/2$"))+
scale_x_continuous(breaks = seq(0.3, 0.6, by = 0.05))+
scale_y_continuous(breaks = seq(0, 1.6, by = 0.2))+
theme_bw()+
theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank())+
theme(legend.position = c(0.8,0.6))+
theme(legend.title = element_blank())
